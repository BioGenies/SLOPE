<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>An introduction to SLOPE • SLOPE</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="An introduction to SLOPE">
<meta property="og:description" content="SLOPE">
<meta property="og:image" content="https://jolars.github.io/SLOPE/logo.svg">
<meta name="robots" content="noindex">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">SLOPE</a>
        <span class="version label label-danger" data-toggle="tooltip" data-placement="bottom" title="In-development version">0.2.1.9000</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/introduction.html">An introduction to SLOPE</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    News
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li class="dropdown-header">Releases</li>
    <li>
      <a href="https://larssonjohan.com/post/slope-0-2-0/">Version 0.2.0</a>
    </li>
    <li class="divider">
    <li>
      <a href="../news/index.html">Changelog</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/jolars/SLOPE/">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>An introduction to SLOPE</h1>
                        <h4 class="author">Johan Larsson</h4>
            
            <h4 class="date">2020-04-21</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/jolars/SLOPE/blob/master/vignettes/introduction.Rmd"><code>vignettes/introduction.Rmd</code></a></small>
      <div class="hidden name"><code>introduction.Rmd</code></div>

    </div>

    
    
<div id="background" class="section level2">
<h2 class="hasAnchor">
<a href="#background" class="anchor"></a>Background</h2>
<p>The functions in this package solves problems of the type <span class="math display">\[
\mathrm{minimize}\left\{f(\beta) + J(\beta; \sigma,\lambda) \right\},
\]</span> where the second part of the objective is the sorted L1-norm <span class="math display">\[
J(\beta; \sigma,\lambda) = \sigma \sum_{j=1}^p \lambda_j \lvert \beta \rvert_{(j)},
\]</span> where <span class="math inline">\(\sigma \in \mathbb{R}_{+}\)</span>, <span class="math inline">\(\lambda \in \mathbb{R}_+^p\)</span> and <span class="math inline">\((j)\)</span> represents an rank of the magnitudes of <span class="math inline">\(\beta\)</span> in descending order. <span class="math inline">\(\lambda\)</span> controls the shape of the penalty sequence, which needs to be non-increasing, and <span class="math inline">\(\sigma\)</span> controls the scale of that sequence.</p>
<p>Solving this problem is called SLOPE (Sorted L-One Penalized Estimation) <span class="citation">(Bogdan et al. 2015)</span>.</p>
<p>In this problem, <span class="math inline">\(f(\beta)\)</span> is a smooth and convex objective, which for this package so far includes four models from the family of generalized linear models:</p>
<ul>
<li>Gaussian regression,</li>
<li>binomial regression,</li>
<li>multinomial regression, and</li>
<li>poisson regression.</li>
</ul>
<p>SLOPE is an extension of the lasso <span class="citation">(Tibshirani 1996)</span> and has the ability to lead to sparse solutions given a sufficiently strong regularization. It is also easy to see that SLOPE reduces to the lasso if all elements of the <span class="math inline">\(\lambda\)</span> vector are equal.</p>
<p>The lasso, however, has difficulties with correlated predictors <span class="citation">(Jia and Yu 2010)</span> but this is not the case with SLOPE, which handles this issue by clustering predictors to the same magnitude. This effect is related to the consecutive differences of the <span class="math inline">\(\lambda\)</span> vector: the larger the steps, the more clustering behavior SLOPE exhibits.</p>
</div>
<div id="an-example" class="section level2">
<h2 class="hasAnchor">
<a href="#an-example" class="anchor"></a>An example</h2>
<p>In the following example, we will use the heart data set, for which the response is a cardiac event. (The package contains several data sets to exemplify modeling. Please see the examples in <code><a href="../reference/SLOPE.html">SLOPE()</a></code>.) The main function of the package is <code><a href="../reference/SLOPE.html">SLOPE()</a></code>, which, more or less, serves as an interface for code written in C++. There are many arguments in the function and most of them relate to either the construction of the regularization path or the penalty (<span class="math inline">\(\lambda\)</span>) sequence used. Here we will use the option <code>lambda = "bh"</code>, which used the BH method detailed in <span class="citation">Bogdan et al. (2015)</span> to select the sequence. (Note that it is also possible to manually insert a sequence.)</p>
<div class="sourceCode" id="cb1"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/base/library.html">library</a></span>(<span class="no">SLOPE</span>)

<span class="no">x</span> <span class="kw">&lt;-</span> <span class="no">heart</span>$<span class="no">x</span>
<span class="no">y</span> <span class="kw">&lt;-</span> <span class="no">heart</span>$<span class="no">y</span>

<span class="no">fit</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/SLOPE.html">SLOPE</a></span>(<span class="no">x</span>, <span class="no">y</span>, <span class="kw">family</span> <span class="kw">=</span> <span class="st">"binomial"</span>, <span class="kw">lambda</span> <span class="kw">=</span> <span class="st">"bh"</span>)</pre></body></html></div>
<p>The default print method gives a summary of the regularization path but it is usually more informative to study a plot of the path.</p>
<div class="sourceCode" id="cb2"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.html">plot</a></span>(<span class="no">fit</span>)</pre></body></html></div>
<div class="figure">
<img src="introduction_files/figure-html/unnamed-chunk-2-1.png" alt="Regularization path for a binomial regression model fit to the heart data set." width="576"><p class="caption">
Regularization path for a binomial regression model fit to the heart data set.
</p>
</div>
</div>
<div id="cross-validation" class="section level2">
<h2 class="hasAnchor">
<a href="#cross-validation" class="anchor"></a>Cross-validation</h2>
<p>To determine the strength of regularization, it is almost always necessary to tune the <span class="math inline">\(\lambda\)</span> sequence using resampling. This package features two methods for this: a specification for use with the <strong>caret</strong> package via the function <code><a href="../reference/caretSLOPE.html">caretSLOPE()</a></code> or <code><a href="../reference/trainSLOPE.html">trainSLOPE()</a></code>. While former facilitate easier comparison of SLOPE against other methods as well as a multitude of options for resampling and measuring performance, it does not allow for sparse predictor matrices. We will give an example of <code><a href="../reference/trainSLOPE.html">trainSLOPE()</a></code> here.</p>
<div class="sourceCode" id="cb3"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span>(<span class="fl">924</span>)

<span class="no">x</span> <span class="kw">&lt;-</span> <span class="no">bodyfat</span>$<span class="no">x</span>
<span class="no">y</span> <span class="kw">&lt;-</span> <span class="no">bodyfat</span>$<span class="no">y</span>

<span class="no">tune</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/trainSLOPE.html">trainSLOPE</a></span>(<span class="no">x</span>,
                   <span class="no">y</span>,
                   <span class="kw">q</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="fl">0.1</span>, <span class="fl">0.2</span>),
                   <span class="kw">number</span> <span class="kw">=</span> <span class="fl">5</span>,
                   <span class="kw">solver</span> <span class="kw">=</span> <span class="st">"admm"</span>,
                   <span class="kw">repeats</span> <span class="kw">=</span> <span class="fl">2</span>)</pre></body></html></div>
<p>As before, the plot method offers the best summary.</p>
<div class="sourceCode" id="cb4"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.html">plot</a></span>(<span class="no">tune</span>, <span class="kw">measure</span> <span class="kw">=</span> <span class="st">"mae"</span>) <span class="co"># plot mean absolute error</span></pre></body></html></div>
<div class="figure">
<img src="introduction_files/figure-html/unnamed-chunk-4-1.png" alt="Model tuning results from Gaussian SLOPE on the bodyfat dataset." width="528"><p class="caption">
Model tuning results from Gaussian SLOPE on the bodyfat dataset.
</p>
</div>
<p>Printing the resulting object will display the optimum values</p>
<div class="sourceCode" id="cb5"><html><body><pre class="r"><span class="no">tune</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; trainSLOPE(x = x, y = y, q = c(0.1, 0.2), number = 5, repeats = 2, </span>
<span class="co">#&gt;     solver = "admm")</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Optimum values:</span>
<span class="co">#&gt;     q     sigma measure      mean        se        lo        hi</span>
<span class="co">#&gt; 1 0.1 0.1264807     mae  3.632983 0.1164238  3.369614  3.896352</span>
<span class="co">#&gt; 2 0.2 0.1152445     mse 19.786523 1.1095689 17.276504 22.296542</span></pre></body></html></div>
</div>
<div id="false-discovery-rate" class="section level2">
<h2 class="hasAnchor">
<a href="#false-discovery-rate" class="anchor"></a>False discovery rate</h2>
<p>Under assumptions of orthonormality, SLOPE has been shown to control false discovery rate (FDR) of non-zero coefficients (feature weights) in the model <span class="citation">(Bogdan et al. 2015)</span>. It is in many ways analogous to the Benjamini–Hochberg procedure for multiple comparisons.</p>
<p>Let’s set up a simple experiment to see how SLOPE controls the FDR. We randomly generate data sets with various proportions of true signals. Under this gaussian design with independently and identically distributed columns in <span class="math inline">\(X\)</span>, SLOPE should asymptotically control FDR at the level given by the shape parameter <span class="math inline">\(q\)</span>, which we set to 0.1 in this example.</p>
<div class="sourceCode" id="cb6"><html><body><pre class="r"><span class="co"># proportion of real signals</span>
<span class="no">q</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span>(<span class="fl">0.05</span>, <span class="fl">0.5</span>, <span class="kw">length.out</span> <span class="kw">=</span> <span class="fl">20</span>)
<span class="no">fdr</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/double.html">double</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span>(<span class="no">q</span>))
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span>(<span class="fl">1</span>)

<span class="kw">for</span> (<span class="no">i</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq_along</a></span>(<span class="no">q</span>)) {
  <span class="no">n</span> <span class="kw">&lt;-</span> <span class="fl">1000</span>
  <span class="no">p</span> <span class="kw">&lt;-</span> <span class="no">n</span>/<span class="fl">2</span>
  <span class="no">sigma</span> <span class="kw">&lt;-</span> <span class="fl">1</span>
  <span class="no">problem</span> <span class="kw">&lt;-</span> <span class="kw pkg">SLOPE</span><span class="kw ns">:::</span><span class="fu">randomProblem</span>(<span class="no">n</span>, <span class="no">p</span>, <span class="kw">q</span> <span class="kw">=</span> <span class="no">q</span>[<span class="no">i</span>], <span class="kw">sigma</span> <span class="kw">=</span> <span class="no">sigma</span>)

  <span class="no">x</span> <span class="kw">&lt;-</span> <span class="no">problem</span>$<span class="no">x</span>
  <span class="no">y</span> <span class="kw">&lt;-</span> <span class="no">problem</span>$<span class="no">y</span>
  <span class="no">signals</span> <span class="kw">&lt;-</span> <span class="no">problem</span>$<span class="no">nonzero</span>

  <span class="no">fit</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/SLOPE.html">SLOPE</a></span>(<span class="no">x</span>,
               <span class="no">y</span>,
               <span class="kw">lambda</span> <span class="kw">=</span> <span class="st">"gaussian"</span>,
               <span class="kw">solver</span> <span class="kw">=</span> <span class="st">"admm"</span>,
               <span class="kw">q</span> <span class="kw">=</span> <span class="fl">0.1</span>,
               <span class="kw">sigma</span> <span class="kw">=</span> <span class="no">sigma</span>)

  <span class="no">selected_slope</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span>(<span class="no">fit</span>$<span class="no">nonzeros</span>)
  <span class="no">V</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/sets.html">setdiff</a></span>(<span class="no">selected_slope</span>, <span class="no">signals</span>))
  <span class="no">R</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span>(<span class="no">selected_slope</span>)
  <span class="no">fdr</span>[<span class="no">i</span>] <span class="kw">&lt;-</span> <span class="no">V</span>/<span class="no">R</span>
}

<span class="fu"><a href="https://rdrr.io/r/base/library.html">library</a></span>(<span class="no">lattice</span>)
<span class="fu"><a href="https://rdrr.io/pkg/lattice/man/xyplot.html">xyplot</a></span>(<span class="no">fdr</span> ~ <span class="no">q</span>, <span class="kw">type</span> <span class="kw">=</span> <span class="st">"b"</span>, <span class="kw">ylab</span> <span class="kw">=</span> <span class="st">"FDR"</span>,
       <span class="kw">panel</span> <span class="kw">=</span> <span class="kw">function</span>(<span class="no">...</span>) {
         <span class="fu"><a href="https://rdrr.io/pkg/lattice/man/panel.functions.html">panel.refline</a></span>(<span class="kw">h</span> <span class="kw">=</span> <span class="fl">0.1</span>)
         <span class="fu"><a href="https://rdrr.io/pkg/lattice/man/panel.xyplot.html">panel.xyplot</a></span>(<span class="no">...</span>)
       })</pre></body></html></div>
<div class="figure">
<img src="introduction_files/figure-html/unnamed-chunk-6-1.png" alt="Control of false discovery rate using SLOPE." width="384"><p class="caption">
Control of false discovery rate using SLOPE.
</p>
</div>
<p>SLOPE seems to control FDR at roughly the specified level.</p>
</div>
<div id="references" class="section level2 unnumbered">
<h2 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h2>
<div id="refs" class="references">
<div id="ref-bogdan2015">
<p>Bogdan, Małgorzata, Ewout van den Berg, Chiara Sabatti, Weijie Su, and Emmanuel J. Candès. 2015. “SLOPE - Adaptive Variable Selection via Convex Optimization.” <em>The Annals of Applied Statistics</em> 9 (3): 1103–40. <a href="https://doi.org/10/gfgwzt">https://doi.org/10/gfgwzt</a>.</p>
</div>
<div id="ref-jia2010">
<p>Jia, J., and B. Yu. 2010. “On Model Selection Consistency of the Elastic Net When P <span class="math inline">\(&gt;&gt;\)</span> N.” <em>Statistica Sinica</em> 20 (2): 595–611.</p>
</div>
<div id="ref-tibshirani1996">
<p>Tibshirani, Robert. 1996. “Regression Shrinkage and Selection via the Lasso.” <em>Journal of the Royal Statistical Society: Series B (Methodological)</em> 58 (1): 267–88. <a href="http://www.jstor.org/stable/2346178">http://www.jstor.org/stable/2346178</a>.</p>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Johan Larsson, Jonas Wallin, Malgorzata Bogdan, Ewout van den Berg, Chiara Sabatti, Emmanuel Candes, Evan Patterson, Weijie Su.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.5.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
