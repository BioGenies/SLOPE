% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/SLOBE.R
\name{ABSLOPE}
\alias{ABSLOPE}
\title{Adaptive Bayesian SLOPE}
\usage{
ABSLOPE(
  X,
  Y,
  start = NULL,
  Xinit = NULL,
  a_prior,
  b_prior,
  Covmat = diag(rep(1, length(start))),
  sigma = 1,
  FDR = 0.05,
  tol = 1e-04,
  max_iter = 100L,
  verbose = FALSE,
  BH = TRUE
)
}
\arguments{
\item{Y}{numeric. Response variable.}

\item{start}{the initial vector of regression coefficients for the first
iteration. Default to the LASSO estimator obtained after}

\item{Xinit}{words, words}

\item{a_prior, b_prior}{non-negative parameters of the prior Beta distribution
on theta.}

\item{Covmat}{numeric covariance matrix. Default to identity matrix.}

\item{sigma}{the variance of the noise. Default to 1.}

\item{FDR}{False Discovery Rate. Default to 0.05.}

\item{tol}{optimization tolerance.}

\item{max_iter}{the maximal number of iterations of the optimization
algorithm. Default to 100.}

\item{verbose}{verbosity. Default to FALSE}

\item{BH}{logical. Indicates whether the Benjamini-Hochberg correction for
multiple testing should be used.}

\item{Xmis}{words, words}

\item{known_sigma}{logical. Indicates whether the sigma is known}

\item{known_cov}{logical. Indicates whether the covariance matrix is known.}
}
\description{
Fit a gaussian model regularized with Adaptive Bayesian SLOPE
and handle missing values by Stochastic Approximation of Expected
Maximization (SAEM)
}
\details{
\code{ABSLOPE} is the combination of SLOPE and Spike-and-Slab
LASSO (SSL). This approach relies on iterations of the weighted SLOPE
algorithm and finds the solution by minimizing
\deqn{
 G(Y,X,\beta) + \sum_{j = 1}^{p} w_j \lambda_{r(\beta,j)}|\beta_j|,
}
where \eqn{r(\beta,j) = {1,2,...,p}} is the rank of \eqn{\beta_j}  among
elements in \eqn{\beta} in a descending order. The weight \eqn{w_j} depends
on the posterior probability that a variable \eqn{X_j} is a true predictor
and is calculated based on the prior knowledge and on the  estimator of
\eqn{\beta_j}, the signal sparsity and its average strength from the previous
iterations.
}
\examples{
library(graphics)
library(mice)
X <- airquality[, c("Ozone", "Solar.R", "Wind")]
X <- as.matrix(X)
Y <- airquality$Temp
imp <- mice(X, m = 1, printFlag = FALSE)
Xinit <- as.matrix(complete(imp))
Covmat <- as.matrix(cov(Xinit))
library(glmnet)
obj3<-cv.glmnet(Xinit, Y,standardize=FALSE, intercept=FALSE)
betal<-coefficients(obj3, s='lambda.min');
coefs <- betal[2:length(betal)]
fit <- ABSLOPE(X, Y, start = coefs, Xinit = Xinit, a_prior = 0.01,
b_prior = 0.01, Covmat = diag(rep(1,length(start))), sigma = 1,
FDR = 0.05, tol = 1e-04, max_iter = 100L,
verbose = FALSE, BH = TRUE)
}
\references{
Jiang, W., Bogdan, M., Josse, J., Majewski, S., Miasojedow, B.,
Ročková, V., & TraumaBase® Group. (2021). Adaptive Bayesian SLOPE: Model
Selection with Incomplete Data. Journal of Computational and Graphical
Statistics, 1-25. \doi{10.1080/10618600.2021.1963263}

Bogdan, M., van den Berg, E., Sabatti, C., Su, W., & Candès, E. J. (2015).
SLOPE -- adaptive variable selection via convex optimization. The Annals of
Applied Statistics, 9(3), 1103–1140. \doi{10/gfgwzt}

Ročková, V., & George, E. I. (2018). The spike-and-slab lasso. Journal of
the American Statistical Association, 113(521), 431-444.
\doi{10.1080/01621459.2016.1260469}
}
